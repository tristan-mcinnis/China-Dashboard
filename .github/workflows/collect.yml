name: collect
on:
  schedule:
    # Run 5 times per day to stay within TianAPI free tier limits
    # Times: 06:00, 10:30, 14:00, 18:30, 22:00 Beijing time (UTC+8)
    # Converted to UTC: 22:00, 02:30, 06:00, 10:30, 14:00
    - cron: "0 22 * * *"    # 06:00 Beijing time
    - cron: "30 2 * * *"    # 10:30 Beijing time
    - cron: "0 6 * * *"     # 14:00 Beijing time
    - cron: "30 10 * * *"   # 18:30 Beijing time
    - cron: "0 14 * * *"    # 22:00 Beijing time
  workflow_dispatch:

permissions:
  contents: write

jobs:
  run:
    runs-on: ubuntu-latest
    # Prevent concurrent runs that could cause race conditions
    concurrency:
      group: data-collection
      cancel-in-progress: false
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'  # Cache pip dependencies for faster builds

      - name: Install deps
        run: pip install -r requirements.txt

      - name: Run collectors
        env:
          TIANAPI_API_KEY: ${{ secrets.TIANAPI_API_KEY }}
          WEIBO_COOKIE: ${{ secrets.WEIBO_COOKIE }}
          FX_API_KEY: ${{ secrets.FX_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          TZ: Asia/Shanghai
        run: |
          # Run each collector and track failures with exit codes
          declare -A collector_status
          collectors=(
            "baidu_top"
            "weibo_hot"
            "tencent_wechat_hot"
            "indices_cn"
            "fx_cny"
            "weather_cn"
            "xinhua_rss"
            "thepaper_rss"
            "ladymax"
            "pboc_rates"
            "nbs_monthly"
            "trade_data"
            "property_cn"
            "gov_regulatory"
          )

          failed_collectors=""
          success_count=0
          total_count=${#collectors[@]}

          for collector in "${collectors[@]}"; do
            echo "Running $collector..."
            if python "collectors/${collector}.py" 2>&1; then
              collector_status[$collector]="success"
              success_count=$((success_count + 1))
            else
              collector_status[$collector]="failed"
              failed_collectors="$failed_collectors $collector"
            fi
          done

          # Generate structured JSON status for health monitoring and badges
          timestamp=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
          status_json="{
            \"timestamp\": \"$timestamp\",
            \"success_count\": $success_count,
            \"total_count\": $total_count,
            \"status\": $([ $success_count -eq $total_count ] && echo '"healthy"' || echo '"degraded"'),
            \"failed\": [$(echo $failed_collectors | sed 's/ *$//' | sed 's/^ *//' | sed 's/ /", "/g' | sed 's/^/"/' | sed 's/$/"/')]
          }"

          # Fix empty array case
          if [ -z "$(echo $failed_collectors | tr -d ' ')" ]; then
            status_json="{
              \"timestamp\": \"$timestamp\",
              \"success_count\": $success_count,
              \"total_count\": $total_count,
              \"status\": \"healthy\",
              \"failed\": []
            }"
          fi

          echo "$status_json" > docs/data/health.json

          # Report failures but don't fail the workflow
          if [ -n "$failed_collectors" ]; then
            echo "::warning::Failed collectors:$failed_collectors"
          else
            echo "All $total_count collectors ran successfully"
          fi

      - name: Write to Neon DB
        if: env.DATABASE_URL != ''
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python -c "
          import json, glob
          from collectors.db_writer import write_to_db

          category_map = {
            'indices': 'market', 'fx': 'fx', 'pboc_rates': 'rates',
            'nbs_monthly': 'macro', 'trade_data': 'trade', 'property': 'property',
            'weather': 'market',
            'baidu_top': 'social', 'weibo_hot': 'social', 'tencent_wechat_hot': 'social',
            'xinhua_news': 'news', 'thepaper_news': 'news', 'ladymax_news': 'news',
            'gov_regulatory': 'regulatory',
          }

          for path in glob.glob('docs/data/*.json'):
            name = path.split('/')[-1].replace('.json', '')
            if name == 'health':
              continue
            try:
              with open(path) as f:
                data = json.load(f)
              cat = category_map.get(name, 'general')
              write_to_db(data, category=cat)
              print(f'DB write OK: {name}')
            except Exception as e:
              print(f'DB write failed for {name}: {e}')
          " 2>&1 || echo "::warning::DB writes had errors"

      - name: Commit data
        run: |
          git config user.name "china-snapshot-bot"
          git config user.email "bot@example.com"

          # Stage all data files
          git add docs/data/*.json docs/data/history/*.json 2>/dev/null || true

          # Check if there are actual meaningful changes (not just timestamp updates)
          # by looking at staged changes excluding as_of/timestamp fields
          if git diff --cached --quiet; then
            echo "No changes to commit"
            exit 0
          fi

          # Count how many data files changed (excluding health.json which always changes)
          changed_files=$(git diff --cached --name-only | grep -c '\.json$' || echo 0)

          if [ "$changed_files" -eq 0 ]; then
            echo "No JSON files changed"
            exit 0
          fi

          # Create a descriptive commit message
          timestamp=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
          git commit -m "data: update $timestamp"

          # Push with retry logic for network failures
          max_retries=4
          retry_count=0
          while [ $retry_count -lt $max_retries ]; do
            if git push; then
              echo "Push successful"
              exit 0
            fi
            retry_count=$((retry_count + 1))
            if [ $retry_count -lt $max_retries ]; then
              wait_time=$((2 ** retry_count))
              echo "Push failed, retrying in ${wait_time}s..."
              sleep $wait_time
            fi
          done
          echo "Push failed after $max_retries attempts"
          exit 1
